{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szXr845ZmPxp",
        "outputId": "c9252baf-f07d-43dd-8a81-7158c5424bdd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "RyxeSm0VmsZi"
      },
      "outputs": [],
      "source": [
        "words=[]\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_words = ['?', '!']\n",
        "\n",
        "intents = pd.read_json(\"/content/job_intents.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HH_lnnjSm8Ym"
      },
      "outputs": [],
      "source": [
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "\n",
        "        w = nltk.word_tokenize(pattern)\n",
        "        words.extend(w)\n",
        "\n",
        "        documents.append((w, intent['tag']))\n",
        "\n",
        "\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "RlkETcxbnBQW"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "j6-mBzjynGB9"
      },
      "outputs": [],
      "source": [
        "lm_words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSNySlHgnHhd",
        "outputId": "a43e8048-df4c-4673-940e-2189d6c65caa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"'s\",\n",
              " ',',\n",
              " 'about',\n",
              " 'anyone',\n",
              " 'are',\n",
              " 'awesome',\n",
              " 'bye',\n",
              " 'can',\n",
              " 'day',\n",
              " 'do',\n",
              " 'ekse',\n",
              " 'fact',\n",
              " 'for',\n",
              " 'give',\n",
              " 'good',\n",
              " 'goodbye',\n",
              " 'hello',\n",
              " 'help',\n",
              " 'helpful',\n",
              " 'helping',\n",
              " 'hemanth',\n",
              " 'hey',\n",
              " 'hi',\n",
              " 'hola',\n",
              " 'how',\n",
              " 'interesting',\n",
              " 'is',\n",
              " 'know',\n",
              " 'later',\n",
              " 'me',\n",
              " 'more',\n",
              " 'name',\n",
              " 'ok',\n",
              " 'purpose',\n",
              " 'see',\n",
              " 'some',\n",
              " 'something',\n",
              " 'tell',\n",
              " 'thank',\n",
              " 'thanks',\n",
              " 'that',\n",
              " 'there',\n",
              " 'ungubani',\n",
              " 'what',\n",
              " 'whats',\n",
              " 'who',\n",
              " 'you',\n",
              " 'your',\n",
              " 'yourself']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm_words = sorted(list(set(lm_words)))\n",
        "lm_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L30wpuNwnLU1",
        "outputId": "cd20b07d-5e0a-45fb-8363-cac12d8edb0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "53 documents\n",
            "7 classes ['goodbye', 'greeting', 'hemanth_facts', 'hemanth_info', 'name', 'options', 'thanks']\n",
            "49 unique lemmatized words [\"'s\", ',', 'about', 'anyone', 'are', 'awesome', 'bye', 'can', 'day', 'do', 'ekse', 'fact', 'for', 'give', 'good', 'goodbye', 'hello', 'help', 'helpful', 'helping', 'hemanth', 'hey', 'hi', 'hola', 'how', 'interesting', 'is', 'know', 'later', 'me', 'more', 'name', 'ok', 'purpose', 'see', 'some', 'something', 'tell', 'thank', 'thanks', 'that', 'there', 'ungubani', 'what', 'whats', 'who', 'you', 'your', 'yourself']\n"
          ]
        }
      ],
      "source": [
        "classes = sorted(list(set(classes)))\n",
        "\n",
        "print (len(documents), \"documents\")\n",
        "print (len(classes), \"classes\", classes)\n",
        "print (len(lm_words), \"unique lemmatized words\", lm_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ZX3wZ2MinbJk"
      },
      "outputs": [],
      "source": [
        "pickle.dump(lm_words,open('words.pkl','wb'))\n",
        "pickle.dump(classes,open('classes.pkl','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "yhYlMXIUney7"
      },
      "outputs": [],
      "source": [
        "training = []\n",
        "output_empty = [0] * len(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "YRigV0Funhwb"
      },
      "outputs": [],
      "source": [
        "for doc in documents:\n",
        "    bag = []\n",
        "    pattern_words = doc[0]\n",
        "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
        "\n",
        "    for w in lm_words:\n",
        "        bag.append(1) if w in pattern_words else bag.append(0)\n",
        "\n",
        "    output_row = list(output_empty)\n",
        "    output_row[classes.index(doc[1])] = 1\n",
        "    training.append([bag, output_row])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "qOrQthYfnkYT"
      },
      "outputs": [],
      "source": [
        "random.shuffle(training)\n",
        "training = np.array(training, dtype='object')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GL506DynzlD",
        "outputId": "7c65e387-7c07-4367-e61b-482665dad2d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(53, 2)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training = np.array(training)\n",
        "training.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "MwREh6RVol5S"
      },
      "outputs": [],
      "source": [
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])\n",
        "\n",
        "VALIDATION_SET = (train_x, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "A81eQ8mtouN6"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_y[0]), activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "0AOA84RaoyAw"
      },
      "outputs": [],
      "source": [
        "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
        "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQd6dlLApCvA",
        "outputId": "e3024cc0-6108-49af-dc2a-dc2fc8d7f9ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "11/11 [==============================] - 1s 27ms/step - loss: 1.9768 - accuracy: 0.1321 - val_loss: 1.8768 - val_accuracy: 0.2453\n",
            "Epoch 2/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.8681 - accuracy: 0.2830 - val_loss: 1.7562 - val_accuracy: 0.2642\n",
            "Epoch 3/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.7866 - accuracy: 0.2075 - val_loss: 1.6370 - val_accuracy: 0.3396\n",
            "Epoch 4/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.7529 - accuracy: 0.2830 - val_loss: 1.5208 - val_accuracy: 0.4340\n",
            "Epoch 5/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1.5634 - accuracy: 0.3585 - val_loss: 1.3983 - val_accuracy: 0.6226\n",
            "Epoch 6/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.4818 - accuracy: 0.4717 - val_loss: 1.2639 - val_accuracy: 0.7170\n",
            "Epoch 7/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1.4491 - accuracy: 0.4528 - val_loss: 1.1417 - val_accuracy: 0.7170\n",
            "Epoch 8/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.2074 - accuracy: 0.5849 - val_loss: 1.0127 - val_accuracy: 0.7358\n",
            "Epoch 9/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0945 - accuracy: 0.6792 - val_loss: 0.8779 - val_accuracy: 0.7358\n",
            "Epoch 10/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0267 - accuracy: 0.6792 - val_loss: 0.7724 - val_accuracy: 0.7925\n",
            "Epoch 11/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9252 - accuracy: 0.7170 - val_loss: 0.6755 - val_accuracy: 0.8491\n",
            "Epoch 12/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9527 - accuracy: 0.6226 - val_loss: 0.5749 - val_accuracy: 0.9057\n",
            "Epoch 13/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8689 - accuracy: 0.7170 - val_loss: 0.5098 - val_accuracy: 0.9434\n",
            "Epoch 14/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.8302 - accuracy: 0.7358 - val_loss: 0.4400 - val_accuracy: 0.9434\n",
            "Epoch 15/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.7783 - accuracy: 0.7358 - val_loss: 0.3975 - val_accuracy: 0.9245\n",
            "Epoch 16/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.6175 - accuracy: 0.8491 - val_loss: 0.3473 - val_accuracy: 0.9623\n",
            "Epoch 17/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6285 - accuracy: 0.8113 - val_loss: 0.2957 - val_accuracy: 0.9623\n",
            "Epoch 18/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4317 - accuracy: 0.8868 - val_loss: 0.2456 - val_accuracy: 0.9623\n",
            "Epoch 19/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4545 - accuracy: 0.8679 - val_loss: 0.2122 - val_accuracy: 0.9811\n",
            "Epoch 20/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.5093 - accuracy: 0.8113 - val_loss: 0.1816 - val_accuracy: 0.9623\n",
            "Epoch 21/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3481 - accuracy: 0.9245 - val_loss: 0.1631 - val_accuracy: 0.9811\n",
            "Epoch 22/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3582 - accuracy: 0.9057 - val_loss: 0.1362 - val_accuracy: 1.0000\n",
            "Epoch 23/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3197 - accuracy: 0.9057 - val_loss: 0.1202 - val_accuracy: 0.9811\n",
            "Epoch 24/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3615 - accuracy: 0.8679 - val_loss: 0.1060 - val_accuracy: 1.0000\n",
            "Epoch 25/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3263 - accuracy: 0.9057 - val_loss: 0.0929 - val_accuracy: 1.0000\n",
            "Epoch 26/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3339 - accuracy: 0.8868 - val_loss: 0.0824 - val_accuracy: 1.0000\n",
            "Epoch 27/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2874 - accuracy: 0.9245 - val_loss: 0.0699 - val_accuracy: 1.0000\n",
            "Epoch 28/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2224 - accuracy: 0.9811 - val_loss: 0.0587 - val_accuracy: 1.0000\n",
            "Epoch 29/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3135 - accuracy: 0.9057 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
            "Epoch 30/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2781 - accuracy: 0.9245 - val_loss: 0.0491 - val_accuracy: 1.0000\n",
            "Epoch 31/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1821 - accuracy: 0.9434 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
            "Epoch 32/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1546 - accuracy: 0.9811 - val_loss: 0.0384 - val_accuracy: 1.0000\n",
            "Epoch 33/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1436 - accuracy: 0.9434 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
            "Epoch 34/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1421 - accuracy: 0.9811 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
            "Epoch 35/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1635 - accuracy: 0.9434 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
            "Epoch 36/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.1926 - accuracy: 0.9245 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
            "Epoch 37/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2281 - accuracy: 0.9434 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
            "Epoch 38/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1471 - accuracy: 0.9811 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
            "Epoch 39/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1095 - accuracy: 0.9811 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
            "Epoch 40/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2058 - accuracy: 0.9434 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
            "Epoch 41/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1767 - accuracy: 0.9623 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
            "Epoch 42/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0859 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 43/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0787 - accuracy: 0.9811 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
            "Epoch 44/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.1211 - accuracy: 0.9623 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 45/250\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2436 - accuracy: 0.8868 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 46/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1184 - accuracy: 0.9623 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 47/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0780 - accuracy: 0.9811 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
            "Epoch 48/250\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0801 - accuracy: 0.9811 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
            "Epoch 49/250\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.1406 - accuracy: 0.9434 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 50/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1382 - accuracy: 0.9245 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 51/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0732 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 52/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1030 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 53/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0779 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 54/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1482 - accuracy: 0.9623 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 55/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1350 - accuracy: 0.9623 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 56/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0981 - accuracy: 0.9811 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 57/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 58/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 59/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 60/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 61/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1218 - accuracy: 0.9623 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 62/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0852 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 63/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1104 - accuracy: 0.9811 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 64/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0728 - accuracy: 0.9811 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 65/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0806 - accuracy: 0.9623 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 66/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0841 - accuracy: 0.9811 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 67/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 68/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0738 - accuracy: 0.9811 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 69/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 70/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1225 - accuracy: 0.9811 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 71/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0781 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 72/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0458 - accuracy: 0.9811 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 73/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 74/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0835 - accuracy: 0.9811 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 75/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0995 - accuracy: 0.9623 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 76/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 77/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 78/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 79/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 80/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0403 - accuracy: 0.9811 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 81/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 9.6623e-04 - val_accuracy: 1.0000\n",
            "Epoch 82/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0622 - accuracy: 0.9811 - val_loss: 9.8405e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 9.4413e-04 - val_accuracy: 1.0000\n",
            "Epoch 84/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 9.1239e-04 - val_accuracy: 1.0000\n",
            "Epoch 85/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 8.8345e-04 - val_accuracy: 1.0000\n",
            "Epoch 86/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 7.9915e-04 - val_accuracy: 1.0000\n",
            "Epoch 87/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 7.1946e-04 - val_accuracy: 1.0000\n",
            "Epoch 88/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0539 - accuracy: 0.9811 - val_loss: 6.9765e-04 - val_accuracy: 1.0000\n",
            "Epoch 89/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0396 - accuracy: 0.9811 - val_loss: 6.6397e-04 - val_accuracy: 1.0000\n",
            "Epoch 90/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 6.1619e-04 - val_accuracy: 1.0000\n",
            "Epoch 91/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 5.8169e-04 - val_accuracy: 1.0000\n",
            "Epoch 92/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0732 - accuracy: 0.9811 - val_loss: 5.8787e-04 - val_accuracy: 1.0000\n",
            "Epoch 93/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 6.5045e-04 - val_accuracy: 1.0000\n",
            "Epoch 94/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 6.4004e-04 - val_accuracy: 1.0000\n",
            "Epoch 95/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 6.2411e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0927 - accuracy: 0.9623 - val_loss: 5.8293e-04 - val_accuracy: 1.0000\n",
            "Epoch 97/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0331 - accuracy: 0.9811 - val_loss: 5.6353e-04 - val_accuracy: 1.0000\n",
            "Epoch 98/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0548 - accuracy: 0.9811 - val_loss: 5.2641e-04 - val_accuracy: 1.0000\n",
            "Epoch 99/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 5.1110e-04 - val_accuracy: 1.0000\n",
            "Epoch 100/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 4.9432e-04 - val_accuracy: 1.0000\n",
            "Epoch 101/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 4.8017e-04 - val_accuracy: 1.0000\n",
            "Epoch 102/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0561 - accuracy: 0.9811 - val_loss: 4.5460e-04 - val_accuracy: 1.0000\n",
            "Epoch 103/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 4.3896e-04 - val_accuracy: 1.0000\n",
            "Epoch 104/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 4.2595e-04 - val_accuracy: 1.0000\n",
            "Epoch 105/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 4.1653e-04 - val_accuracy: 1.0000\n",
            "Epoch 106/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 4.2856e-04 - val_accuracy: 1.0000\n",
            "Epoch 107/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0450 - accuracy: 0.9811 - val_loss: 4.4527e-04 - val_accuracy: 1.0000\n",
            "Epoch 108/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 4.4448e-04 - val_accuracy: 1.0000\n",
            "Epoch 109/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 4.3166e-04 - val_accuracy: 1.0000\n",
            "Epoch 110/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 3.9692e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 3.6367e-04 - val_accuracy: 1.0000\n",
            "Epoch 112/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0814 - accuracy: 0.9811 - val_loss: 3.9884e-04 - val_accuracy: 1.0000\n",
            "Epoch 113/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0574 - accuracy: 0.9811 - val_loss: 7.2202e-04 - val_accuracy: 1.0000\n",
            "Epoch 114/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0627 - accuracy: 0.9811 - val_loss: 5.9640e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 4.8830e-04 - val_accuracy: 1.0000\n",
            "Epoch 116/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 4.9801e-04 - val_accuracy: 1.0000\n",
            "Epoch 117/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0513 - accuracy: 0.9623 - val_loss: 4.0615e-04 - val_accuracy: 1.0000\n",
            "Epoch 118/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 3.6240e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 3.2857e-04 - val_accuracy: 1.0000\n",
            "Epoch 120/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 3.0372e-04 - val_accuracy: 1.0000\n",
            "Epoch 121/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.9001e-04 - val_accuracy: 1.0000\n",
            "Epoch 122/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 2.8096e-04 - val_accuracy: 1.0000\n",
            "Epoch 123/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0326 - accuracy: 0.9811 - val_loss: 2.9768e-04 - val_accuracy: 1.0000\n",
            "Epoch 124/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 3.3025e-04 - val_accuracy: 1.0000\n",
            "Epoch 125/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 3.0279e-04 - val_accuracy: 1.0000\n",
            "Epoch 126/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 2.5300e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0480 - accuracy: 0.9811 - val_loss: 2.7856e-04 - val_accuracy: 1.0000\n",
            "Epoch 128/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0327 - accuracy: 0.9811 - val_loss: 2.8283e-04 - val_accuracy: 1.0000\n",
            "Epoch 129/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0810 - accuracy: 0.9811 - val_loss: 2.5188e-04 - val_accuracy: 1.0000\n",
            "Epoch 130/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 2.2213e-04 - val_accuracy: 1.0000\n",
            "Epoch 131/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0632 - accuracy: 0.9811 - val_loss: 2.4531e-04 - val_accuracy: 1.0000\n",
            "Epoch 132/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 9.1268e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 134/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0240 - accuracy: 0.9811 - val_loss: 5.7037e-04 - val_accuracy: 1.0000\n",
            "Epoch 135/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0633 - accuracy: 0.9623 - val_loss: 3.7814e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 3.9545e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 3.5700e-04 - val_accuracy: 1.0000\n",
            "Epoch 138/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 0.9811 - val_loss: 3.0155e-04 - val_accuracy: 1.0000\n",
            "Epoch 139/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 2.9199e-04 - val_accuracy: 1.0000\n",
            "Epoch 140/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0259 - accuracy: 0.9811 - val_loss: 2.7617e-04 - val_accuracy: 1.0000\n",
            "Epoch 141/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0575 - accuracy: 0.9811 - val_loss: 2.6778e-04 - val_accuracy: 1.0000\n",
            "Epoch 142/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.5570e-04 - val_accuracy: 1.0000\n",
            "Epoch 143/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 2.4133e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/250\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 2.1345e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.9338e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 1.6842e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0492 - accuracy: 0.9811 - val_loss: 1.5665e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.4794e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/250\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.4428e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0292 - accuracy: 0.9811 - val_loss: 1.4781e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.4864e-04 - val_accuracy: 1.0000\n",
            "Epoch 152/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.4383e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/250\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0267 - accuracy: 0.9811 - val_loss: 1.3914e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/250\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0588 - accuracy: 0.9623 - val_loss: 1.3348e-04 - val_accuracy: 1.0000\n",
            "Epoch 155/250\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0308 - accuracy: 0.9811 - val_loss: 1.9327e-04 - val_accuracy: 1.0000\n",
            "Epoch 156/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0376 - accuracy: 0.9811 - val_loss: 2.0761e-04 - val_accuracy: 1.0000\n",
            "Epoch 157/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.4801e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.3594e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0338 - accuracy: 0.9811 - val_loss: 1.3780e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 1.3352e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 1.3071e-04 - val_accuracy: 1.0000\n",
            "Epoch 162/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.3315e-04 - val_accuracy: 1.0000\n",
            "Epoch 163/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0823 - accuracy: 0.9623 - val_loss: 1.2384e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 1.1397e-04 - val_accuracy: 1.0000\n",
            "Epoch 165/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 9.9367e-05 - val_accuracy: 1.0000\n",
            "Epoch 166/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 9.1580e-05 - val_accuracy: 1.0000\n",
            "Epoch 167/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 8.3753e-05 - val_accuracy: 1.0000\n",
            "Epoch 168/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 8.0706e-05 - val_accuracy: 1.0000\n",
            "Epoch 169/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0352 - accuracy: 0.9811 - val_loss: 8.9677e-05 - val_accuracy: 1.0000\n",
            "Epoch 170/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 9.6565e-05 - val_accuracy: 1.0000\n",
            "Epoch 171/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 9.5294e-05 - val_accuracy: 1.0000\n",
            "Epoch 172/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0356 - accuracy: 0.9811 - val_loss: 8.9246e-05 - val_accuracy: 1.0000\n",
            "Epoch 173/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 8.6153e-05 - val_accuracy: 1.0000\n",
            "Epoch 174/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 7.8317e-05 - val_accuracy: 1.0000\n",
            "Epoch 175/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 7.4984e-05 - val_accuracy: 1.0000\n",
            "Epoch 176/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 7.2678e-05 - val_accuracy: 1.0000\n",
            "Epoch 177/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 7.2135e-05 - val_accuracy: 1.0000\n",
            "Epoch 178/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 7.0569e-05 - val_accuracy: 1.0000\n",
            "Epoch 179/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 7.2181e-05 - val_accuracy: 1.0000\n",
            "Epoch 180/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 7.6368e-05 - val_accuracy: 1.0000\n",
            "Epoch 181/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 7.6923e-05 - val_accuracy: 1.0000\n",
            "Epoch 182/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 7.6630e-05 - val_accuracy: 1.0000\n",
            "Epoch 183/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 7.9592e-05 - val_accuracy: 1.0000\n",
            "Epoch 184/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0515 - accuracy: 0.9623 - val_loss: 6.6352e-05 - val_accuracy: 1.0000\n",
            "Epoch 185/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 6.0253e-05 - val_accuracy: 1.0000\n",
            "Epoch 186/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 5.9054e-05 - val_accuracy: 1.0000\n",
            "Epoch 187/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0311 - accuracy: 0.9811 - val_loss: 5.7410e-05 - val_accuracy: 1.0000\n",
            "Epoch 188/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 5.7672e-05 - val_accuracy: 1.0000\n",
            "Epoch 189/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 5.7456e-05 - val_accuracy: 1.0000\n",
            "Epoch 190/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 5.5085e-05 - val_accuracy: 1.0000\n",
            "Epoch 191/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 5.4397e-05 - val_accuracy: 1.0000\n",
            "Epoch 192/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0329 - accuracy: 0.9811 - val_loss: 5.4107e-05 - val_accuracy: 1.0000\n",
            "Epoch 193/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 5.1007e-05 - val_accuracy: 1.0000\n",
            "Epoch 194/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 4.8615e-05 - val_accuracy: 1.0000\n",
            "Epoch 195/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 4.7861e-05 - val_accuracy: 1.0000\n",
            "Epoch 196/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 4.8290e-05 - val_accuracy: 1.0000\n",
            "Epoch 197/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.8552e-05 - val_accuracy: 1.0000\n",
            "Epoch 198/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.8089e-05 - val_accuracy: 1.0000\n",
            "Epoch 199/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0222 - accuracy: 0.9811 - val_loss: 1.0539e-04 - val_accuracy: 1.0000\n",
            "Epoch 200/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.6968e-04 - val_accuracy: 1.0000\n",
            "Epoch 201/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 3.4493e-04 - val_accuracy: 1.0000\n",
            "Epoch 202/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.2706e-04 - val_accuracy: 1.0000\n",
            "Epoch 203/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.3608e-04 - val_accuracy: 1.0000\n",
            "Epoch 204/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2079e-04 - val_accuracy: 1.0000\n",
            "Epoch 205/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.1126e-04 - val_accuracy: 1.0000\n",
            "Epoch 206/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.0643e-04 - val_accuracy: 1.0000\n",
            "Epoch 207/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.0426e-04 - val_accuracy: 1.0000\n",
            "Epoch 208/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.0016e-04 - val_accuracy: 1.0000\n",
            "Epoch 209/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 9.2589e-05 - val_accuracy: 1.0000\n",
            "Epoch 210/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 8.7346e-05 - val_accuracy: 1.0000\n",
            "Epoch 211/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 8.1324e-05 - val_accuracy: 1.0000\n",
            "Epoch 212/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 7.5305e-05 - val_accuracy: 1.0000\n",
            "Epoch 213/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 7.0570e-05 - val_accuracy: 1.0000\n",
            "Epoch 214/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 6.7855e-05 - val_accuracy: 1.0000\n",
            "Epoch 215/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 6.5464e-05 - val_accuracy: 1.0000\n",
            "Epoch 216/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 6.3221e-05 - val_accuracy: 1.0000\n",
            "Epoch 217/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 6.0527e-05 - val_accuracy: 1.0000\n",
            "Epoch 218/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 5.9114e-05 - val_accuracy: 1.0000\n",
            "Epoch 219/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.7281e-05 - val_accuracy: 1.0000\n",
            "Epoch 220/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 5.5182e-05 - val_accuracy: 1.0000\n",
            "Epoch 221/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0880 - accuracy: 0.9811 - val_loss: 5.6072e-05 - val_accuracy: 1.0000\n",
            "Epoch 222/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0208 - accuracy: 0.9811 - val_loss: 9.8693e-05 - val_accuracy: 1.0000\n",
            "Epoch 223/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.3164e-04 - val_accuracy: 1.0000\n",
            "Epoch 224/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.1974e-04 - val_accuracy: 1.0000\n",
            "Epoch 225/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0305 - accuracy: 0.9811 - val_loss: 1.0845e-04 - val_accuracy: 1.0000\n",
            "Epoch 226/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 9.6311e-05 - val_accuracy: 1.0000\n",
            "Epoch 227/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 8.8166e-05 - val_accuracy: 1.0000\n",
            "Epoch 228/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 7.9322e-05 - val_accuracy: 1.0000\n",
            "Epoch 229/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 7.5375e-05 - val_accuracy: 1.0000\n",
            "Epoch 230/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 7.3221e-05 - val_accuracy: 1.0000\n",
            "Epoch 231/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 7.0847e-05 - val_accuracy: 1.0000\n",
            "Epoch 232/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 7.0793e-05 - val_accuracy: 1.0000\n",
            "Epoch 233/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 6.9721e-05 - val_accuracy: 1.0000\n",
            "Epoch 234/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 6.7362e-05 - val_accuracy: 1.0000\n",
            "Epoch 235/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 6.6363e-05 - val_accuracy: 1.0000\n",
            "Epoch 236/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 6.2400e-05 - val_accuracy: 1.0000\n",
            "Epoch 237/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 5.6974e-05 - val_accuracy: 1.0000\n",
            "Epoch 238/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 5.4229e-05 - val_accuracy: 1.0000\n",
            "Epoch 239/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 5.2032e-05 - val_accuracy: 1.0000\n",
            "Epoch 240/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0353 - accuracy: 0.9811 - val_loss: 5.3534e-05 - val_accuracy: 1.0000\n",
            "Epoch 241/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0547 - accuracy: 0.9811 - val_loss: 4.6271e-05 - val_accuracy: 1.0000\n",
            "Epoch 242/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 4.5483e-05 - val_accuracy: 1.0000\n",
            "Epoch 243/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 4.8821e-05 - val_accuracy: 1.0000\n",
            "Epoch 244/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0416 - accuracy: 0.9623 - val_loss: 4.9319e-05 - val_accuracy: 1.0000\n",
            "Epoch 245/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 4.7633e-05 - val_accuracy: 1.0000\n",
            "Epoch 246/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 5.0126e-05 - val_accuracy: 1.0000\n",
            "Epoch 247/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 5.0381e-05 - val_accuracy: 1.0000\n",
            "Epoch 248/250\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 4.9297e-05 - val_accuracy: 1.0000\n",
            "Epoch 249/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 4.8546e-05 - val_accuracy: 1.0000\n",
            "Epoch 250/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 4.7250e-05 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(np.array(train_x), np.array(train_y), epochs=250, validation_data = VALIDATION_SET, batch_size=5, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbVScmndpP4P",
        "outputId": "3548d718-36e8-45bd-c4a4-b81c20b94cb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('chatbot_model.h5', history)\n",
        "print(\"model Saved\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
